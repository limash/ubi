{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Pool\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.simplefilter(action='ignore', category=pd.core.common.SettingWithCopyWarning)\n",
    "    \n",
    "plt.style.use('bmh')\n",
    "plt.rcParams['figure.figsize'] = [14, 8]  # width, height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is code slightly modified from the sklearn docs here:\n",
    "# https://scikit-learn.org/stable/auto_examples/model_selection/plot_cv_indices.html#sphx-glr-auto-examples-model-selection-plot-cv-indices-py\n",
    "def plot_cv_indices(cv, X, y, group, ax, n_splits, lw=10):\n",
    "    \"\"\"Create a sample plot for indices of a cross-validation object.\"\"\"\n",
    "    \n",
    "    cmap_cv = plt.cm.coolwarm\n",
    "\n",
    "    jet = plt.cm.get_cmap('jet', 256)\n",
    "    seq = np.linspace(0, 1, 256)\n",
    "    _ = np.random.shuffle(seq)   # inplace\n",
    "    cmap_data = ListedColormap(jet(seq))\n",
    "\n",
    "    # Generate the training/testing visualizations for each CV split\n",
    "    for ii, (tr, tt) in enumerate(cv.split(X=X, y=y, groups=group)):\n",
    "        # Fill in indices with the training/test groups\n",
    "        indices = np.array([np.nan] * len(X))\n",
    "        indices[tt] = 1\n",
    "        indices[tr] = 0\n",
    "\n",
    "        # Visualize the results\n",
    "        ax.scatter(range(len(indices)), [ii + .5] * len(indices),\n",
    "                   c=indices, marker='_', lw=lw, cmap=cmap_cv,\n",
    "                   vmin=-.2, vmax=1.2)\n",
    "\n",
    "    # Plot the data classes and groups at the end\n",
    "    ax.scatter(range(len(X)), [ii + 1.5] * len(X),\n",
    "               c=y, marker='_', lw=lw, cmap=plt.cm.Set3)\n",
    "\n",
    "    ax.scatter(range(len(X)), [ii + 2.5] * len(X),\n",
    "               c=group, marker='_', lw=lw, cmap=cmap_data)\n",
    "\n",
    "    # Formatting\n",
    "    yticklabels = list(range(n_splits)) + ['target', 'day']\n",
    "    ax.set(yticks=np.arange(n_splits+2) + .5, yticklabels=yticklabels,\n",
    "           xlabel='Sample index', ylabel=\"CV iteration\",\n",
    "           ylim=[n_splits+2.2, -.2], xlim=[0, len(y)])\n",
    "    ax.set_title('{}'.format(type(cv).__name__), fontsize=15)\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store target, features, and folds labels from a dataframe into several tfrecords\n",
    "def save_tfrecords(input):\n",
    "    df, idx, folder = input\n",
    "    def _float_feature(list_of_floats):\n",
    "        return tf.train.Feature(float_list=tf.train.FloatList(value=list_of_floats))\n",
    "    \n",
    "    # def _int_feature(list_of_ints):\n",
    "    #     return tf.train.Feature(int64_list=tf.train.Int64List(value=list_of_ints))\n",
    "    \n",
    "    target_index = 4\n",
    "    features_start_index, features_postfinal_index = 5, 305\n",
    "    out_file = None\n",
    "    for i, row in tqdm(enumerate(df.itertuples())):\n",
    "        if i % 30000 == 0:\n",
    "            if out_file is not None:\n",
    "                out_file.close()\n",
    "            filename = f'data/tfrecords/{folder}/fold{idx}/{row[0]}.tfrec'\n",
    "            out_file = tf.io.TFRecordWriter(filename)\n",
    "        feature_dict = {}\n",
    "        feature_dict[row._fields[target_index]] = _float_feature([row[target_index]])\n",
    "        feature_dict['features'] = _float_feature(row[features_start_index:features_postfinal_index])\n",
    "\n",
    "        example = tf.train.Example(features=tf.train.Features(feature=feature_dict))\n",
    "        out_file.write(example.SerializeToString())\n",
    "    out_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data and choose cv strategy\n",
    "N_SPLITS = 5\n",
    "df = pd.read_parquet('data/train_low_mem.parquet')\n",
    "cv = GroupKFold(n_splits=N_SPLITS)\n",
    "# fig, ax = plt.subplots()\n",
    "# plot_cv_indices(cv, df, y, df['investment_id'], ax, N_SPLITS, lw=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_indices = []\n",
    "valid_indices = []\n",
    "for train_index, valid_index in cv.split(df, groups=df['investment_id']):\n",
    "    train_indices.append(train_index)\n",
    "    valid_indices.append(valid_index)\n",
    "del cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, valid_df = df.iloc[train_indices[idx]], df.iloc[valid_indices[idx]]\n",
    "del df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split train_df to save tfrecords in parallel\n",
    "size = 800000\n",
    "list_of_train_dfs = [(train_df.iloc[i:i+size,:], idx, 'train') for i in range(0, len(train_df), size)]\n",
    "number_dfs = len(list_of_train_dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Train data recording.\")\n",
    "# save train tfrecords\n",
    "with Pool(number_dfs) as p:\n",
    "    p.map(save_tfrecords, list_of_train_dfs)\n",
    "del train_df\n",
    "del list_of_train_dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split valid_df\n",
    "size = 210000\n",
    "list_of_valid_dfs = [(valid_df.iloc[i:i+size,:], idx, 'validation') for i in range(0, len(valid_df), size)]\n",
    "number_dfs = len(list_of_valid_dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Validation data recording.\")\n",
    "with Pool(number_dfs) as p:\n",
    "    p.map(save_tfrecords, list_of_valid_dfs)\n",
    "\n",
    "print(\"Validation data pickling.\")\n",
    "# save a validation dataframe\n",
    "valid_df.to_pickle(f\"data/tfrecords/validation/fold{idx}/validation.pkl\") \n",
    "del valid_df\n",
    "del list_of_valid_dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6363654707a3d37b300368bbc9381cc10fc6ca39658e75fc3e05c7cbeb1913f8"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 ('ml')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
